---
permalink: /guides/working-with-pipelines/
layout: guide-markdown
title: Build and deploy applications with pipelines
duration: 30 minutes
releasedate: 2020-02-19
description: Explore how to use Pipelines with Application Stacks
tags: ['Pipelines, Application stacks']
guide-category: pipelines
---

<!-- Note:
> This repository contains the guide documentation source. To view
> the guide in published form, view it on the [website](https://kabanero.io/guides/{projectid}.html).
-->

<!--
//
//	Copyright 2019, 2020 IBM Corporation and others.
//
//	Licensed under the Apache License, Version 2.0 (the "License");
//	you may not use this file except in compliance with the License.
//	You may obtain a copy of the License at
//
//	http://www.apache.org/licenses/LICENSE-2.0
//
//	Unless required by applicable law or agreed to in writing, software
//	distributed under the License is distributed on an "AS IS" BASIS,
//	WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
//	See the License for the specific language governing permissions and
//	limitations under the License.
//
-->

Kabanero uses [pipelines](https://github.com/tektoncd/pipeline/tree/master/docs#usage) to illustrate a continuous input and continuous delivery (CI/CD) workflow. Kabanero provides a set of default tasks and pipelines that can be associated with application stacks.  These pipelines leverage steps & tasks that provide the following capabilities:
- build the application stack
- enforce goverance opolicy
- publish the image to a container registry
- scan the published image
- sign the image
- Retag an image
- deploy the application to the Kubernetes cluster
- promote service to a gitops repo (This feature is Tech Preview in this release)
- deploy the application using Kustomize (This feature is Tech Preview in this release)

You can also create additional tasks and pipelines or customize the pre-built pipelines and tasks to suit your needs. All tasks and pipelines are activated by  [Kabanero's standard Kubernetes operator](https://github.com/kabanero-io/kabanero-operator).

To learn more about pipelines and creating new tasks, see [the pipeline tutorial](https://github.com/tektoncd/pipeline/blob/master/docs/tutorial.md).

## Kabanero tasks and pipelines

A set of Kabanero tasks and pipelines are provided in the [Kabanero pipelines repository](https://github.com/kabanero-io/kabanero-pipelines/tree/master/pipelines/).  Details of some of the primary pipelines and tasks are described below.

### Events pipelines

The tasks & pipelines provided in the [Kabanero pipelines repository events directory](https://github.com/kabanero-io/kabanero-pipelines/tree/master/pipelines/incubator/events) are geared to work with the Kabanero events operator.  Please follow the instructions in <TODO: Link to this guide when published: https://github.com/kabanero-io/guides/blob/master/publish/integrating-events-operator/integrating-events-operator.md> to setup the organization webhook and EventMediator to drive these pipelines.

There are 4 primary pipelines provided here to help illustrate the following work flow.

* **Jane makes an update to the application and creates a new PR**

This will trigger the `build-pl` which will build the application code and build the application image using the `build-task`.  The PR will be updated with the results of the build pipeline.

* **The PR is then merged into master**

This will trigger the `build-push-promote-pl` which will enforce governance policy, build the code, optionally sign the image, push it to the image registry, scan the image, optionally deploy the image on the cluster, and optionally promote the service to the configured gitops repo.  

The pipeline invokes the following tasks to accomplish the steps listed: 
  * [build-push-promote-task.yaml](https://github.com/kabanero-io/kabanero-pipelines/blob/master/pipelines/incubator/events/build-push-promote-task.yaml)
    This task first does a pre-build goverance policy check to validate the stack version in the app repo is allowed to build based on the goverance policy that is configured. It then builds a container image from the artifacts in the git-source repository by using `appsody build`. The appsody build command leverages [Buildah](https://github.com/containers/buildah) to build the image. The command also generates the `app-deploy.yaml` that is used for deployment. If there is already a copy of the `app-deploy.yaml` file in the source repository, it is merged with the new one generated by this step. After the image is built, the image is then optionally signed if the necessary configuration is setup. Please refer to the [image signing operator](https://github.com/kabanero-io/kabanero-security/tree/master/pipelines/samples/signing-operator) for more information on configuring image signing.  The image is then pushed to the configured image registry.
        
    (Tech preview feature) A configmap called `gitops-map` in the Kabanero namespace can optionally be configured to promote the service to a gitops repo after the build.  The step will invoke the [`services promote`](https://github.com/rhd-gitops-example/services) command to create a PR with the updated `app-deploy.yaml` file in the configured gitops repo.  The following key value pairs should be setup in the configmap:
    ```
    kind: ConfigMap 
    apiVersion: v1 
    metadata:
      name: gitops-map
      namespace: kabanero
    data:
      gitops-repo-enabled: <true or false>
      gitops-repo-url: <can be specified here if common for all the pipelines in the cluster or in the event mediator for specific versions of the pipeline> 
      gitops-commit-user-name: <user_name_to_commit_using>
      gitops-commit-user-email: <user_email_to_commit_using>
    ```
    
    A secret called `gitops-token` also has to be created in the Kabanero namspace.  An example yaml is shown below to create the secret.
    ```
    apiVersion: v1
    kind: Secret
    metadata:
      name: gitops-token
    annotations:
      tekton.dev/git-0: https://github.com
    namespace: kabanero
    type: kubernetes.io/basic-auth
    stringData:
      username: <gitops_repo_username>
      password: <gitops_repo_access_token>
    ```
       
  * [deploy-task.yaml](https://github.com/kabanero-io/kabanero-pipelines/blob/master/pipelines/incubator/events/deploy-task.yaml)
    If the `webhooks-tekton-local-deploy` property is set to true in the mediator, the image is deployed to the namespace configured in the `app-deploy.yaml`.  By default, the application will be deployed in the `kabanero` namespace.
  
  * [image-scan-task.yaml](https://github.com/kabanero-io/kabanero-pipelines/blob/master/pipelines/incubator/events/image-scan-task.yaml)
    The `image-scan-task` task will initiate a container scan of the image published by the `build-push-task` using OpenSCAP.  The results of the scan are published in the logs of the task.

* **A release of the application is created**

This will trigger the `image-retag-pl` pipeline which leverages the [image-retag-task.yaml](https://github.com/kabanero-io/kabanero-pipelines/blob/master/pipelines/incubator/events/image-retag-task.yaml) to create a new tag of the image to match with the git release.

* **PR in Gitops repo is merged** (This feature is Tech Preview in this release)
When the PR that was created by the promote step of the `build-push-promote-pl` is merged in the gitops repo, it will trigger  the `deploy-kustomize-pl` pipeline which leverages the [deploy-kustomize-task.yaml](https://github.com/kabanero-io/kabanero-pipelines/blob/master/pipelines/incubator/events/deploy-kustomize-task.yaml) to trigger a deployment to the environment configured in the gitops repo.

### Legacy incubator pipelines (Deprecated in Kabanero 0.9.0)

The set of Kabanero tasks and pipelines are provided in the [Kabanero pipelines repository](https://github.com/kabanero-io/kabanero-pipelines/tree/master/pipelines/incubator) are being deprecated. These tasks and pipelines were intended to illustrate work flows with the Tekton webhooks extenstion which is also being deprecated.  Please use the events pipelines and tasks mentioned in the section above instead.

Details of some of the primary pipelines and tasks are described below.

### The build, push and deploy pipeline

- [build-deploy-pl.yaml](https://github.com/kabanero-io/kabanero-pipelines/blob/master/pipelines/incubator/build-deploy-pl.yaml)

This is the primary pipeline that showcases a majority of the tasks supplied in the Kabanero pipelines incubator repo. It enforces governance policy, builds the code, optionally signs the image, pushes it to the image registry, scans the image, and will conditionally deploy the image on the cluster.  When running the pipeline via a webhook, the pipeline leverages the triggers functionality to conditionally deploy the application only when a pull request is merged in the git repo.  Other actions that trigger the pipeline run will enforce governance policy, build, push, and scan the image.

### Tasks

- [build-push-task.yaml](https://github.com/kabanero-io/kabanero-pipelines/blob/master/pipelines/incubator/build-push-task.yaml)

   This file builds a container image from the artifacts in the git-source repository by using `appsody build`.  The appsody build command leverages the [Buildah](https://github.com/containers/buildah) options. After the image is built, the image is published to the container registry that is configured. The build-push-task also generates the `app-deploy.yaml` that is used by the `deploy-task`.  If there is already a copy of the `app-deploy.yaml` file in the source repository, it is merged with the new one generated by this step. 
   
   To enable image signing, please refer to the [image signing operator](https://github.com/kabanero-io/kabanero-security/tree/master/pipelines/samples/signing-operator).

- [deploy-task.yaml](https://github.com/kabanero-io/kabanero-pipelines/blob/master/pipelines/incubator/deploy-task.yaml)

   `Deploy-task` uses the `app-deploy.yaml` file to deploy the application to the cluster by using the application deployment operator. By default, the pipelines run and deploy the application in the `kabanero` namespace. If you want to deploy the application in a different namespace, update the `app-deploy.yaml` file to point to that namespace.

- [image-scan-task.yaml](https://github.com/kabanero-io/kabanero-pipelines/blob/master/pipelines/incubator/image-scan-task.yaml)

  The `image-scan-task` task will initiate a container scan of the image published by the `build-push-task` using OpenSCAP.  The results of the scan are published in the logs of the task.
  
For more tasks and pipelines, see [the kabanero-pipelines repo](https://github.com/kabanero-io/kabanero-pipelines).

### Associating pipelines with applications stacks in Kabanero CRD for events pipelines

The pipelines can be associated with an application stack in the Kabanero custom resource definition (CRD). This is an example CRD:

```yaml
apiVersion: kabanero.io/v1alpha1
kind: Kabanero
metadata:
  name: kabanero
spec:
  version: "0.9.0"
  stacks:
    repositories:
    - name: central
      https:
        url: https://github.com/kabanero-io/collections/releases/download/0.9.0/kabanero-index.yaml
    pipelines:
    - id: default
      sha256: 14d59b7ebae113c18fb815c2ccfd8a846c5fbf91d926ae92e0017ca5caf67c95
      https:
        url: https://github.com/kabanero-io/kabanero-pipelines/releases/download/0.9.0/kabanero-events-pipelines.tar.gz
```

When the Kabanero operator activates the CRD, it associates the pipelines in the pipelines archive with each of the stacks in the stack hub.  The default pipelines are intended to work with all the stacks in the stack hub in the previous example.  When the operator activates all the pipeline resources (such as the tasks, trigger bindings, and pipelines) in the archive, it will  add a suffix to the name of the resource with the shorted Digest of the pipelines archive.  This provides an easy way to have multiple versions of the same pipeline active on the cluster.

### Associating pipelines with applications stacks in Kabanero CRD for legacy pipelines

The pipelines can be associated with an application stack in the Kabanero custom resource definition (CRD). This is an example CRD:

```yaml
apiVersion: kabanero.io/v1alpha1
kind: Kabanero
metadata:
  name: kabanero
spec:
  version: "0.6.0"
  stacks:
    repositories:
    - name: central
      https:
        url: https://github.com/kabanero-io/collections/releases/download/0.5.0/kabanero-index.yaml
    pipelines:
    - id: default
      sha256: 14d59b7ebae113c18fb815c2ccfd8a846c5fbf91d926ae92e0017ca5caf67c95
      https:
        url: https://github.com/kabanero-io/kabanero-pipelines/releases/download/0.6.0/default-kabanero-pipelines.tar.gz
```

When the Kabanero operator activates the CRD, it associates the pipelines in the pipelines archive with each of the stacks in the stack hub.  The default pipelines are intended to work with all the stacks in the stack hub in the previous example. All of the pipeline-related resources (such as the tasks, trigger bindings, and pipelines) prefix the name of the resource with the keyword `StackId`.  When the operator activates these resources, it replaces the keyword with the name of the stack it is activating.

### Creating and updating tasks and pipelines

The default tasks and pipelines can be updated by forking the Kabanero Pipelines repo and editing the files under `pipelines/`.  The easiest way to generate the archive for use by the Kabanero CRD is to run the [package.sh](https://github.com/kabanero-io/kabanero-pipelines/blob/master/ci/package.sh) script. The script generates the archive files  with the necessary pipeline artifacts and a `manifest.yaml` file that describes the contents of the archive.  Copy the `package.sh` file to the root directory of your pipelines project and run it.  It generates the pipelines archive file under `ci/assests`.

Alternatively, you can run the Travis build against a release of your pipelines repo, which also generates the archive file with a `manifest.yaml` file and attaches it to your release.

<!--
// =================================================================================================
// Using stacks that are published to internal and private registries by pipelines
// =================================================================================================
-->

## Using stacks that are published to internal and private registries in pipelines

If you are publishing your application stack images to any registry other than Docker hub, you can specify your custom registry when you initialize a stack by using the `--stack-registry` option in the `appsody init` command.  Specifying a custom registry updates the stack name in the `.appsody-config.yaml` to include the registry information that is consumed by the pipeline.  

Alternatively, you can use a configmap to configure the custom repository from which your pipelines pulls the container images.

1. After you clone the `kabanero-pipelines` repository, find the `stack-image-registry-map.yaml` configmap template file. Add your container registry URL to this file in place of the `default-stack-image-registry-url` statement.

   ```shell
   cd kabanero-pipelines/pipelines/sample-helper-files/
   vi stack-image-registry-map.yaml
   ```

1. If your custom application stack image is stored in an internal OpenShift registry, the service account that is associated with the pipelines must be configured to allow the pipelines to pull from the internal registry without configuring a secret. If your custom application stack is stored in a container registry with an external route, follow these steps to set up a Kubernetes secret:

   - Find the `default-stack-image-registry-secret.yaml` template file in the cloned kabanero-pipelines repo (`kabanero-pipelines/pipelines/sample-helper-files/`) and update it with the username and token password for the container registry URL you specified previously.

   - Create a Base64 format version of the username and password for the external route container registry URL.

      ```shell
      echo -n <your-registry-username> | base64
      echo -n <your-registry-password> | base64
      ```

   - Update the `default-stack-image-registry-secret.yaml` file with the Base64 formatted username and password.

      ```shell
      vi default-stack-image-registry-secret.yaml
      ```

   - Apply the `default-stack-image-registry-secret.yaml` file to the cluster

      ```shell
      oc apply -f default-stack-image-registry-secret.yaml
      ```

1. Apply the following configmap file, which will set your container registry.

   ```shell
   oc apply -f stack-image-registry-map.yaml
   ```

**NOTE:** If a value is specified in both the config map and in the `.appsody-config.yaml` and they are different, the config map takes precedence.

<!--
// =================================================================================================
// Running pipelines
// =================================================================================================
-->

## Running pipelines

Explore how to use pipelines to build and manage application stacks.

### Prerequisites

1. [Kabanero foundation](https://github.com/kabanero-io/kabanero-foundation) must be installed on a supported Kubernetes deployment.

1. [A pipelines dashboard](https://github.com/tektoncd/dashboard) is installed by default with Kabanero's Kubernetes operator. To find the pipelines dashboard URL, login to your cluster and run the `oc get routes` command or in the Kabanero landing page.

1. A persistent volume must be configured. See the following section for details.

1. Secrets for the git repo (if private) and image repository

### Getting started

Follow these steps:

1. Set up a persistent volume to run pipelines

   Pipelines require a configured volume that is used by the framework to share data across tasks.  The pipeline run creates a Persistent Volume Claim (PVC) with a requirement for five GB of persistent volume.

   - Static persistent volumes

      If you are not running your cluster on a public cloud, you can set up a static persistent volume using NFS. For an example of how to use static persistent volume provisioning, see [Static persistent volumes](https://github.com/kabanero-io/kabanero-pipelines/blob/master/docs/VolumeProvisioning.md#static-persistent-volumes).

   - Dynamic volume provisioning

      If you run your cluster on a public cloud, you can set up a dynamic persistent volume by using your cloud provider’s default storage class. For an example of how to use dynamic persistent volume provisioning, see [Dynamic volume provisioning](https://github.com/kabanero-io/kabanero-pipelines/blob/master/docs/VolumeProvisioning.md#dynamic-volume-provisioning).

1. Create secrets

   Git secrets must be created in the `kabanero` namespace and associated with the service account that runs the pipelines. To configure secrets using the pipelines dashboard, see [Create secrets](https://kabanero.io/docs/ref/general/configuration/tekton-webhooks.html#create-secrets).

   Alternatively, you can [configure secrets in the Kubernetes console or set them up by using the Kubernetes CLI](https://docs.okd.io/latest/dev_guide/secrets.html#creating-secrets).

### Running pipelines by using the pipelines dashboard webhook extension

You can use the [pipelines dashboard webhook extension](https://github.com/tektoncd/experimental/blob/master/webhooks-extension/docs/GettingStarted.md) to drive pipelines that automatically build and deploy an application whenever you update the code in your Git repo. Events such as commits or pull requests can be set up to automatically trigger pipeline runs.

### Running pipelines by using a script

If you are developing a new pipeline and want to test it in a tight loop, you might want to use a script or manually drive the pipeline.

1. Log in to your cluster. For example,

   ```shell
   oc login <master node IP>:8443
   ```

1. Clone the pipelines repo

   ```shell
   git clone https://github.com/kabanero-io/kabanero-pipelines
   ```

1. Run the following script with the appropriate parameters

   ```shell
   cd ./pipelines/sample-helper-files/./manual-pipeline-run-script.sh -r [git_repo of the Appsody project] -i [docker registery path of the image to be created] -c [application stack name of which pipeline to be run]"
   ```

   - The following example is configured to use the dockerhub container registry:

      ```shell
       ./manual-pipeline-run-script.sh -r https://github.com/mygitid/appsody-test-project -i index.docker.io/mydockeid/my-java-microprofile-image -c java-microprofile"
      ```

   - The following example is configured to use the local OpenShift container registry:

      ```shell
       ./manual-pipeline-run-script.sh -r https://github.com/mygitid/appsody-test-project -i docker-registry.default.svc:5000/kabanero/my-java-microprofile-image -c java-microprofile"
      ```

### Running pipelines manually from the command line

Follow these steps to run a pipeline directly from the command line:

1. Login to your cluster. For example,

   ```shell
   oc login <master node IP>:8443
   ```

1. Clone the pipelines repo.

   ```shell
   git clone https://github.com/kabanero-io/kabanero-pipelines
   cd kabanero-pipelines
   ```

1. Create pipeline resources.

   Use the `pipeline-resource-template.yaml` file to create the `PipelineResources`. The `pipeline-resource-template.yaml` is provided in the pipelines [/pipelines/sample-helper-files](https://github.com/kabanero-io/kabanero-pipelines/tree/master/pipelines/sample-helper-files) directory. Update the docker-image URL. You can use the sample GitHub repo or update it to point to your own GitHub repo.

1. After you update the file, apply it as shown in the following example:

   ```shell
   oc apply -f <stack-name>-pipeline-resources.yaml
   ```

### Activating tasks and pipelines

The installations that activate the featured application stacks also activate the tasks and pipelines. If you are creating a new task or pipeline, activate it manually, as shown in the following example.

```shell
oc apply -f <task.yaml>
oc apply -f <pipeline.yaml>
```

### Running the pipeline

A sample `manual-pipeline-run-template.yaml` file is provided in the [/pipelines/sample-helper-files](https://github.com/kabanero-io/kabanero-pipelines/tree/master/pipelines/sample-helper-files) directory. Rename the template file to a name of your choice (for example, pipeline-run.yaml), and update the file to replace `application-stack-name` with the name of your application stack. After you update the file, run it as shown in the following example.

```shell
oc apply -f <application-stack-name>-pipeline-run.yaml
```

<!--
// =================================================================================================
// Checking the status of the pipeline run
// =================================================================================================
-->

## Checking the status of the pipeline run

You can check the status of the pipeline run from the Kubernetes console,
command line, or pipelines dashboard.

### Checking pipeline run status from the pipelines dashboard

1. Log in to the pipelines dashboard and click `Pipeline runs'
in the sidebar menu.

1. Find your pipeline run in the list and click it to check the status and find logs. You can see logs
and status for each step and task.

### Checking pipeline run status from the command line

Enter the following command in the terminal:

```shell
oc get pipelineruns
oc -n kabanero describe pipelinerun.tekton.dev/<pipeline-run-name>
```

You can also see pods for the pipeline runs, for which you can specify `oc describe` and `oc logs` to get more details.

If the pipeline run was successful, you can see a Docker image in our Docker registry and a pod that’s running your application.

<!--
// =================================================================================================
// Troubleshooting
// =================================================================================================
-->

## Troubleshooting

To find solutions for common issues and troubleshoot problems with pipelines, see the [Pipelines Troubleshooting Guide](https://github.com/kabanero-io/kabanero-pipelines/blob/master/docs/Troubleshooting.md).

### Related links

- [Kabanero Pipelines repository](https://github.com/kabanero-io/kabanero-pipelines)
- [Tekton Pipeline tutorial](https://github.com/tektoncd/pipeline/blob/master/docs/tutorial.md)
